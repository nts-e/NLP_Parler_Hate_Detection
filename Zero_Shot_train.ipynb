{"cells":[{"cell_type":"markdown","metadata":{"id":"7cT0h-e5Mykr"},"source":["#**Zero Shot - Train Set Enrichment Cycle**"]},{"cell_type":"markdown","metadata":{"id":"A3Wz2UJ0Oi5k"},"source":["## Pipe:\n","Bert<br>\n","Zero-Shot for hate speech classification.<br>\n","Zero-Shot on <a href=https://github.com/jagol/nli-for-hate-speech-detection/blob/main/configs/hypotheses_en.json>target group</a><br><br>\n","(Inspired by this <a href=https://aclanthology.org/2022.trac-1.10.pdf>article</a>)<br>"]},{"cell_type":"markdown","metadata":{"id":"8-CkWtXodqFR"},"source":["## Instructions:\n","1. Use the Presets cell to configure data and model.<br>\n","2. Input file from the <a href=https://zenodo.org/record/4442460>Parler Open Dataset</a>.<br>\n","2. Run all cells.<br>\n","3. Collect the result csv from DATA_FOLDER_PATH.<br>"]},{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hkhc10wNrGt"},"outputs":[],"source":["# !pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4giRzM7NtHJ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import transformers\n","import tensorflow as tf\n","import pickle\n","from transformers import BartForSequenceClassification, BartTokenizer\n","import json\n","from datetime import datetime\n","from tensorflow.keras import models, layers, metrics, losses, optimizers"]},{"cell_type":"markdown","metadata":{"id":"SFyde3sfTOPi"},"source":["# Code"]},{"cell_type":"markdown","source":["## Presets"],"metadata":{"id":"J1asmHTUdlG6"}},{"cell_type":"code","source":["ITERATION                     = 0 # Use 0,1, or 2\n","\n","USE_GOOGLE_DRIVE_FOR_FILES    = False\n","DATA_FOLDER_PATH              = \"./Data/\"\n","#MODEL_FOLDER_PATH             = \"./Data/models/\"\n","hate_classifier_threshold     = 0.5\n","hate_target_hypothesis        = 'That contains hate '\n","hate_zeroshot_threshold       = 0.7\n","hate_target_threshold         = 0.7\n","bert_model                    = f'BERT_{ITERATION}'\n","posts_file                    = f'parler_data000000000000.sampled50000.{ITERATION}'\n","posts_group                   = 1"],"metadata":{"id":"_tWujoOTdhzV","executionInfo":{"status":"ok","timestamp":1675879885840,"user_tz":-120,"elapsed":248,"user":{"displayName":"Axenic IL","userId":"12500427820375269677"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u9qxKHNAzZNm"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccTY9ar1zbUL"},"outputs":[],"source":["def load_data(big_dataset_file_name):\n","  df = pd.read_json(f'{DATA_FOLDER_PATH}csv_files/{big_dataset_file_name}.ndjson')\n","  return df\n","\n","def load_csv(filename):\n","  df = pd.read_csv(f'{DATA_FOLDER_PATH}csv_files/{filename}.csv')\n","  return df\n"]},{"cell_type":"markdown","metadata":{"id":"wZEpeD9qTRL_"},"source":["## Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Hbu75dyPLUj"},"outputs":[],"source":["classifier_tokenizer = None\n","classifier_model = None\n","\n","def load_classifier_model():\n","  # load tokenizer\n","  global classifier_tokenizer\n","  base_model_name = 'distilbert-base-uncased'\n","  classifier_tokenizer = transformers.DistilBertTokenizer.from_pretrained(base_model_name) \n","\n","  # load bert model\n","  config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2) # Nitzan - config here is irrelevant\n","  dbert_tf = transformers.TFDistilBertModel.from_pretrained(base_model_name, config=config, trainable=False)\n","\n","  return models.load_model(f'{DATA_FOLDER_PATH}models/{bert_model}.h5', custom_objects={'TFDistilBertModel': dbert_tf})\n","\n","def classify(posts):\n","  max_length = 190\n","  X_tokenized = classifier_tokenizer(posts.to_list(), padding='max_length', max_length = max_length, truncation=True, return_attention_mask=True)\n","  y_pred_proba = classifier_model.predict({'input_ids': np.array(X_tokenized['input_ids']), 'input_attention': np.array(X_tokenized['attention_mask'])})\n","  y_pred = np.array([y_pred_proba > hate_classifier_threshold], dtype=int).flatten()\n","  return y_pred\n"]},{"cell_type":"markdown","metadata":{"id":"PGlAVvMglXr1"},"source":["## Zero Shot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gm5p_14xljL2"},"outputs":[],"source":["def load_zeroshot_model():\n","  tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n","  model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n","  return model, tokenizer\n","\n","def zeroshot_hate_classify(premise):\n","  hypothesis1 = 'That contains hate speech'\n","# run through model pre-trained on MNLI\n","  input_ids1 = zeroshot_tokenizer.encode(premise, hypothesis1, return_tensors='pt')\n","  logits1 = zeroshot_model(input_ids1)[0]\n","  entail_contradiction_logits1 = logits1[:,[0,2]]\n","  prob1 = entail_contradiction_logits1.softmax(dim=1)\n","  true_prob1 = prob1[:,1].item() \n","\n","  return(true_prob1)\n","\n","def zeroshot_hate_target_classify(premise, target):\n","  hypothesis2 = hate_target_hypothesis + target\n","  \n","  input_ids2 = zeroshot_tokenizer.encode(premise, hypothesis2, return_tensors='pt')\n","  logits2 = zeroshot_model(input_ids2)[0]\n","  entail_contradiction_logits2 = logits2[:,[0,2]]\n","  prob2 = entail_contradiction_logits2.softmax(dim=1)\n","  true_prob2 = prob2[:,1].item() \n","  \n","  return(true_prob2)\n","\n","def zeroshot_identify_hate_target(premise):\n","  targets = ['women', 'trans people', 'queer people', 'gay', 'black people', 'asian people', 'people of color', 'indigenous people',\n","             'muslim people', 'immigrants', 'jewish people', 'christian people', 'hindu people'\n","             ]\n","  imax = 0\n","  pmax = 0\n","  for i in range(len(targets)):\n","    p = zeroshot_hate_target_classify(premise, targets[i])\n","    if p > pmax:\n","      imax = i\n","      pmax = p\n","\n","  if pmax > hate_target_threshold:\n","    return targets[imax]\n","  else:\n","    return None\n"]},{"cell_type":"markdown","metadata":{"id":"XeSQ-TVcUWOW"},"source":["# Tests / Demo"]},{"cell_type":"markdown","metadata":{"id":"V0cDmckBE0Lq"},"source":["## Init models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cg-qjFbLwODz"},"outputs":[],"source":["classifier_model = load_classifier_model()\n","zeroshot_model, zeroshot_tokenizer = load_zeroshot_model()"]},{"cell_type":"markdown","metadata":{"id":"4Q6uPVHfE4uk"},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plvuKtVpUVfe"},"outputs":[],"source":["posts = load_csv(posts_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxBJfz0dRKHb"},"outputs":[],"source":["posts['bert'] = classify(posts['body'])\n","posts[posts['bert'] == 1]"]},{"cell_type":"markdown","metadata":{"id":"TWia3nOpFCaw"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3K0pZuGPtSi"},"outputs":[],"source":["def train_cycle(df):\n","  df['target'] = -1\n","  for i in range(df.shape[0]):\n","    print(i, end = \", \")\n","    bert = df.iloc[i]['bert']\n","    print (f'bert hate:{bert}', end = \", \")\n","    hate = zeroshot_hate_classify(df.iloc[i]['body']) > hate_zeroshot_threshold\n","    df.at[i, 'hate'] = hate\n","    if hate == 1:\n","      print ('zero hate')\n","      if bert == 0:\n","        continue\n","      target = zeroshot_identify_hate_target(df.iloc[i]['body'])\n","      if target != None:\n","        print(target)\n","        df.at[i, 'target'] = target\n","      else:\n","        df.at[i, 'target'] = 0\n","  return df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJHGQ5dpYw57"},"outputs":[],"source":["res = train_cycle(posts)\n","res.to_csv(f'{DATA_FOLDER_PATH}csv_files/parler_unannotated_predictions_{ITERATION}.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1n8AcWPZJturqd7zBpEv3wH9NwLSXLBM6","timestamp":1669998486285},{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1669016403594}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}